{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T07:32:55.554997Z",
     "start_time": "2024-12-19T07:32:44.493593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BertTokenizer"
   ],
   "id": "8efe485215735817",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T07:32:55.566321Z",
     "start_time": "2024-12-19T07:32:55.561180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if MPS is available and set the device accordingly\n",
    "device = torch.device(\"cpu\")"
   ],
   "id": "5432853f5e888939",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-19T07:32:55.899560Z",
     "start_time": "2024-12-19T07:32:55.833650Z"
    }
   },
   "source": [
    "# Load the custom tokenizer\n",
    "tokenizer_dir = \"archive/custom_tokenizer\"  # Path to the saved tokenizer directory\n",
    "custom_tokenizer = BertTokenizer.from_pretrained(tokenizer_dir)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T07:32:59.727064Z",
     "start_time": "2024-12-19T07:32:55.909805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the pre-trained Sentence-BERT model\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Replace the default tokenizer with the custom tokenizer\n",
    "model.tokenizer = custom_tokenizer"
   ],
   "id": "6703a927fc70df2a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T07:33:00.091889Z",
     "start_time": "2024-12-19T07:32:59.739714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Query and document examples\n",
    "query = \"Donald Trump recently visited the UK.\"\n",
    "documents = [\n",
    "    \"The President of the United States visited the UK.\",\n",
    "    \"The UK was visited by the President of the United States.\",\n",
    "    \"ONU congress decides to ban nuclear weapons.\",\n",
    "    \"The sky is blue.\",\n",
    "    \"The sun is shining.\",\n",
    "    \"Recipe for a delicious cake.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings for documents and query\n",
    "doc_embeddings = model.encode(documents)\n",
    "query_embedding = model.encode([query])\n",
    "\n",
    "# Normalize embeddings\n",
    "doc_embeddings = doc_embeddings / np.linalg.norm(doc_embeddings, axis=1, keepdims=True)\n",
    "query_embedding = query_embedding / np.linalg.norm(query_embedding, axis=1, keepdims=True)\n",
    "\n",
    "# Create FAISS index\n",
    "dimension = doc_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "index.add(np.array(doc_embeddings))\n",
    "\n",
    "# Search for the most similar documents\n",
    "k = len(documents)\n",
    "distances, indices = index.search(np.array(query_embedding), k)\n",
    "\n",
    "# Display results\n",
    "for i, idx in enumerate(indices[0]):\n",
    "    fragment = documents[idx]\n",
    "    score = distances[0][i]\n",
    "    print(f\"Fragment: {fragment}\\nGrad de similitudine: {score:.2f}\")\n"
   ],
   "id": "c730f5f946808721",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fragment: The sky is blue.\n",
      "Grad de similitudine: 0.98\n",
      "Fragment: The sun is shining.\n",
      "Grad de similitudine: 0.58\n",
      "Fragment: ONU congress decides to ban nuclear weapons.\n",
      "Grad de similitudine: 0.55\n",
      "Fragment: Recipe for a delicious cake.\n",
      "Grad de similitudine: 0.47\n",
      "Fragment: The President of the United States visited the UK.\n",
      "Grad de similitudine: 0.43\n",
      "Fragment: The UK was visited by the President of the United States.\n",
      "Grad de similitudine: 0.39\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
